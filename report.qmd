---
title: "Textual Analysis of Federal Reserve Communications and Crypto Market Volatility: An Augmented GARCH Approach"
format: 
  html: 
    code-fold: true
    code-summary: "show code"
editor: visual
message: false
warning: false
---

### Abstract

With the increasing institutional adoption of cryptocurrencies, Bitcoin has transitioned from a niche speculative asset to a financial instrument highly sensitive to macroeconomic signaling. While the impact of numerical interest rate decisions on crypto markets is well-documented, the nuanced effects of central bank verbal communication remain under-explored, especially during periods of aggressive monetary tightening. This paper investigates the impact of Federal Reserve communications on Bitcoin market volatility during the 2022-2024 inflationary cycle. By applying **Natural Language Processing** techniques to FOMC statements and minutes, we construct a time-varying "Hawkish-Dovish" sentiment index. We then employ an **Augmented GARCH-MIDAS framework** to analyze the transmission of these textual sentiment shocks to Bitcoin's conditional volatility. The empirical results demonstrate that the "tone" of Fed communication is a significant driver of market risk. Specifically, we find strong evidence of **asymmetry**: unanticipated "Hawkish" (restrictive) sentiment triggers significantly higher volatility persistence compared to "Dovish" signals. Furthermore, the inclusion of textual sentiment variables significantly improves the model's goodness-of-fit compared to baseline models relying solely on policy rate changes. These findings challenge the "digital gold" narrative, providing evidence that Bitcoin functions as a high-beta risk asset that is deeply intertwined with U.S. monetary policy uncertainty.

Key words: Natural Language Processing; Augmented GARCH-MIDAS; crypto currency; Textual analysis

### Introduction

Early empirical literature characterized Bitcoin as a hybrid asset, exhibiting features of both a medium of exchange and a speculative store of value similar to gold **(Dyhrberg, 2016)**. Consistent with its decentralized design, previous studies covering the 2015-2018 period suggested that Bitcoin's volatility was largely idiosyncratic and insulated from U.S. monetary policy shocks **(Nguyen et al., 2019)**.

However, the landscape has shifted dramatically. With the acceleration of institutional adoption and the approval of spot ETFs, the cryptocurrency market has become increasingly integrated with global finance. Recent evidence suggests that Federal Reserve announcements significantly impact crypto-asset dynamics **(Corbet et al., 2017)**. Furthermore, in traditional markets, research indicates that the textual sentiment of central bank statements often exerts a more profound impact on asset volatility than numerical interest rate changes alone **(Rosa, 2011)**. Yet, it remains unclear whether this "textual channel" of monetary policy transmission has fully permeated the modern cryptocurrency market during the recent tightening cycle.

To address this question, this paper employs **Natural Language Processing (NLP)** to quantify the sentiment of Federal Reserve communications. Using an **Augmented GARCH framework**, we test the volatility spillover effects of these textual signals on the cryptocurrency market, specifically examining whether market reactions exhibit asymmetry in response to hawkish versus dovish tones.

### Literature review

### Data & Descriptive statistics

The bit coin data was collected through Binance. And I manually curated the list of tweets.

```{r}
library(quantmod)
library(dplyr)
library(zoo)
library(ggplot2)

# 1. download the data of Bitcoin and Nasdaq
getSymbols("BTC-USD", src = "yahoo", from = "2015-01-01", to = "2024-12-31")
getSymbols("^NDX",    src = "yahoo", from = "2015-01-01", to = "2024-12-31")

# 2. calculate the daily log return
btc_ret <- dailyReturn(Cl(`BTC-USD`), type = "log")
ndx_ret <- dailyReturn(Cl(`NDX`),    type = "log")

# 3. correspond them by date 
ret_merged <- merge(btc_ret, ndx_ret, join = "inner")
colnames(ret_merged) <- c("btc", "ndx")

# 4. calculate the rolling windows
window <- 90  
roll_cor <- rollapply(
  ret_merged,
  width = window,
  FUN = function(x) cor(x[,"btc"], x[,"ndx"], use = "complete.obs"),
  by.column = FALSE,
  align = "right"
)

# 5. covert into dataframe and draw a plot
cor_df <- data.frame(
  date = index(roll_cor),
  cor  = coredata(roll_cor)
)

ggplot(cor_df, aes(x = date, y = cor)) +
  geom_line() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title    = paste0("Figure1.",window, "-day Rolling Correlation: Bitcoin vs Nasdaq-100"),
    x        = "Date",
    y        = "Rolling Pearson correlation"
  ) +
  theme_minimal()

```

Figure1 plots 90 day rolling pearson correlation between daily log return of Bitcoin and Nasdaq-100 index from 2015 to present. Before 2017, we find that the rolling pearson correlation between daily log return of Bitcoin and Nasdaq-100 is low. From 2017 to 2020, we find the number has a larger volatility and move upward generally speaking. After 2020, the number increased sharply and reached all time high. And then, the number range from 0.2 to 0.5 most of the time. This gradual increase in correlation suggests that Bitcoin has become more integrated with mainstream financial markets, which motivates our subsequent GARCH-based analysis of its volatility dynamics and spillovers.

```{r}
library(DT)
datatable(btc_ret,
          rownames = FALSE,
          options = list(
            pageLength = 10,
            lengthMenu = c(5,10,20,50),
            searching = TRUE,
            dom = 'Bfrtip',
            buttons = c('copy','csv','excel','pdf','print')
          ))
```

```{r}
library(stargazer)
library(dplyr)
BTC_RET <- btc_ret |>
  arrange(Date)|>
  mutate(ret = Close /lag(Close)-1)|>
  filter(!is.na(ret))

stargazer(BTC_RET$ret,
          type = "html",
          title = "BTC daily return(specific parameters)",
          digits = 4,
          summary.stat = c("mean","sd","min","max","p25","p75","median"))
```

```{r}
library(readxl)
d1 <- read_excel("text.xlsx")
d2 <- read.csv("dictionary.csv")
```

"Standard sentiment dictionaries(e.g.,Harvard IV-4)often misclassify financial terminology. Following the seminal work of Loughran and McDonald(2011), who argue the necessity of domain-specific lexicons in financial research, this paper constructs a specialized 'hawkish-dovish' dictionary tailored for central bank communications.

Unlike corporate earnings calls where 'positive' or 'negative' tones are paramount, the primary driver of asset volatility in the context of the Federal Reserve is the policy inclination towards tightening(Hawkish) or easing(Dovish). Drawing on thw monetary policy word lists established by apel and Blix(2017) and recent crypto-macro literature, we define two specific sets of keywords:

Hawkish Terms: Words associated with  inflation concerns and restrictive policy

Dovish Terms: words associated with deflation concerns and accomodative policy

To quantify the quanlitative content of the FOMC statements, we employ a Net Sentiment Score(NSS) approach. For each statement t, we calculate the frequency of Hawkish(Ht) and Dovish(Dt) terms. To control for the varying length of documents over time, the raw counts are normalized by the total number of sentiment-charged  words.

The net Hawkish-Dovish Index is defined as follows:

             St = (Ht- Dt)/(Ht+Dt)
             
Where: 
 Ht represents the count of Hawkish keywords in the statement at time t.
 Dt represents the count of Dovish keywords in the statement at time t.
 
 This index ranges from -1 to 1. A positive value (St >0) indicates a net hawkish tone, suggesting potential interest rate hikes or liquidity withdrawal. Conversely, a negative value indicated a net Dovish(accommodative) tone. A value of zero implied a neutral stance.
 
```{r}
library(tidyverse)
library(tidytext)
library(stringr)
library(lubridate) 
library(readr) 


dovish <- read.csv("dovish.csv")
dovish <- dovish |> mutate(sentiment = "dovish") |> select(Word,sentiment)
hawkish <- read.csv("hawkish.csv")
hawkish <- hawkish |> mutate(sentiment = "hawkish")|> select(Word,sentiment)

custom_dictionary <- bind_rows(hawkish,dovish)

write_csv(custom_dictionary, "custom_dictionary.csv")

library(dplyr)
library(stringr) 

custom_dictionary <- read.csv("custom_dictionary.csv", stringsAsFactors = FALSE)


custom_dictionary <- custom_dictionary %>%
  mutate(Word = tolower(Word)) 







raw_data <- read_csv("fomc_data.csv", show_col_types = FALSE)


raw_data <- raw_data %>%
  mutate(date = as.Date(date))


tidy_text <- raw_data %>%
  unnest_tokens(word, text) 

sentiment_result <- tidy_text %>%
  inner_join(custom_dictionary, by = c("word" = "Word"))


sentiment_index <- sentiment_result |>
  

  count(date, sentiment) %>%
  

  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  

  bind_rows(tibble(date = as.Date(character()), hawkish = numeric(), dovish = numeric())) %>%
  mutate(
    hawkish = if("hawkish" %in% names(.)) hawkish else 0,
    dovish  = if("dovish" %in% names(.)) dovish else 0
  ) %>%
  

  mutate(
    total_sentiment_words = hawkish + dovish,
  
    net_score = (hawkish - dovish) / (total_sentiment_words + 0.001)
  ) %>%
  
 
  select(date, hawkish, dovish, net_score) %>%
  arrange(date) 



# 3.1 打印前几行看看
print(head(sentiment_index))

# 3.2 保存为新的 CSV 文件 (这个文件就是你 GARCH 模型的输入变量)
write_csv(sentiment_index, "fomc_sentiment_index.csv")
cat("计算完成！结果已保存为 'fomc_sentiment_index.csv'\n")

# ==============================================================================
# 步骤 4: 画图检查 (Visualize)
# 这一步是为了放在论文里，证明你的指数捕捉到了政策变化
# ==============================================================================

ggplot(sentiment_index, aes(x = date, y = net_score)) +
  # 画柱状图
  geom_col(aes(fill = net_score > 0), show.legend = FALSE) +
  # 添加趋势线
  geom_line(color = "black", alpha = 0.3) +
  # 颜色设置：红色代表鹰派(>0)，蓝色代表鸽派(<0)
  scale_fill_manual(values = c("TRUE" = "firebrick", "FALSE" = "steelblue")) +
  # 设置标题和标签
  labs(
    title = "Federal Reserve Hawkish-Dovish Sentiment Index (2022-present)",
    subtitle = "Derived from FOMC Statements using Textual Analysis",
    y = "Net Sentiment Score (Hawkish > 0, Dovish < 0)",
    x = "Meeting Date"
  ) +
  # 设置 y 轴范围 (-1 到 1)
  ylim(-1, 1) +
  # 主题美化
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))
```
 
### Methodology

```{r}
library(rugarch)
library(xts)
library(tidyverse)

set.seed(123)
dates <- seq(as.Date("2022-01-01"),as.Date("2024-01-01"),by = "day")
n<- length(dates)
btc_returns <- rnorm(n,mean = 0, sd = 0.05)

fed_sentiment <- rnorm(n, mean = 0, sd = 1) 

data_xts <- xts(cbind(btc_returns, fed_sentiment), order.by = dates)
colnames(data_xts) <- c("Returns", "Sentiment")

head(data_xts)


regressors <- matrix(data_xts$Sentiment, ncol = 1)

spec_augmented <- ugarchspec(
  
 
  mean.model = list(
    armaOrder = c(1, 0), 
    include.mean = TRUE
  ),
  
  
  variance.model = list(
    model = "eGARCH",       
    garchOrder = c(1, 1),
    external.regressors = regressors 
  ),
  
 
  distribution.model = "std" 
)

# --- 4. 拟合模型 (Fit the Model) ---
fit_augmented <- ugarchfit(spec = spec_augmented, data = data_xts$Returns)

# --- 5. 查看结果 ---
 show(fit_augmented) # 运行这行看完整报告，下面展示如何提取核心指标

# 提取系数矩阵
print(coef(fit_augmented))
```

### Empirical Results

### Discussion& limitations

### Conclusion

### References

